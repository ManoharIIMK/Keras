{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Classifying bearings with a Convolutional Neural Network using TensorFlow, CV2\n",
    "# https://www.kaggle.com/stevenhurwitt/cats-vs-dogs-using-a-keras-convnet\n",
    "'''\n",
    "These are the steps need to follow while writing Tensorflow:\n",
    "\n",
    "Step 1) Import the necessary pacakges and data\n",
    "Step 2) Transform the data\n",
    "Step 3) Construct the tensor\n",
    "Step 4) Build the model\n",
    "Step 5) Train and evaluate the model\n",
    "Step 6) Improve the mode\n",
    "\n",
    "-install Keras first time, import pandas, numpy \n",
    "\n",
    "-Import all libraries as below\n",
    "\n",
    "-Import Numpy. If it is first time, we can pip install\n",
    "\n",
    "-Import os and matplotlib\n",
    "\n",
    "-progress bars to Python code is with tqdm. Install it and import.\n",
    "\n",
    "'''\n",
    "\n",
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 8, 3, 22, 15, 41, 616235)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start=datetime.now()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eshwar'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"E:/IIM/TensorFlow/warranty/Bearings/\")\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eshwar'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TensorFlow Fold makes it easy to implement deep-learning models that operate over data of varying size and structure\n",
    "\n",
    "Firsr, change the working directory where we have the images for input.\n",
    "\n",
    "1. create image folders for test and train.\n",
    "2. If not in the desired, change/set the working directory to that path as below where the image files exists.\n",
    "'''\n",
    "\n",
    "os.chdir(\"E:/IIM/TensorFlow/warranty/Bearings/\")\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set Path to test directory\n",
    "Set path to train directory\n",
    "'''\n",
    "\n",
    "TEST_DIR  = \"E:/IIM/TensorFlow/warranty/Bearings/test\"\n",
    "TRAIN_DIR  = \"E:/IIM/TensorFlow/warranty/Bearings/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 256\n",
    "COLS = 256\n",
    "ROWS2 = 64\n",
    "COLS2 = 64\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "train_guds =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'gud' in i]\n",
    "train_bads =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'bad' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/trainbad.10.JPG'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/traingud.10.JPG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_guds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/trainbad.1.JPG'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/test1.JPG'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(TRAIN_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice datasets for test and training\n",
    "\n",
    "train_images = train_guds[:197] + train_bads[:281]\n",
    "random.shuffle(train_images)\n",
    "test_images =  test_images[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "IMG_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "define the classification label to convert the lable into one-hot array as below\n",
    "'''\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [gud,bad]\n",
    "    #                            [much gud, no bad]\n",
    "    if word_label == 'gud': return [1,0]\n",
    "    #                             [no gud, very bad]\n",
    "    elif word_label == 'bad': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create training data and save it in train_data.npy in the working directory.\n",
    "Convert the image as gray scale image\n",
    "This data can be used in the subsequent steps as needed\n",
    "\n",
    "'''\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create test data and save it in train_data.npy in the working directory.\n",
    "Convert the image as gray scale image\n",
    "This data can be used in the subsequent steps as needed\n",
    "\n",
    "'''\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/traingud.73.JPG'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 691.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train = create_train_data()\n",
    "# If we have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 772.29it/s]\n"
     ]
    }
   ],
   "source": [
    "test = process_test_data()\n",
    "# If we have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 990.55it/s]\n"
     ]
    }
   ],
   "source": [
    "test2 = process_test_data()\n",
    "# If we have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 63, 159, 165, ..., 178, 182, 183],\n",
       "        [ 88, 167, 160, ..., 179, 180, 181],\n",
       "        [115, 173, 155, ..., 176, 176, 178],\n",
       "        ...,\n",
       "        [176, 173, 177, ..., 140, 131,  61],\n",
       "        [172, 172, 169, ..., 129, 118,  57],\n",
       "        [169, 175, 169, ..., 127, 107,  60]], dtype=uint8), array([0, 1])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-5c59ca315368>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "train = train.reshape(3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24f4936dba8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'gud' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "sns.countplot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/IIM/TensorFlow/warranty/Bearings/trainbad.10.JPG'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bads[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eshwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-fdfa773bb2e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-a9b954c422d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatdog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-a9b954c422d0>\u001b[0m in \u001b[0;36mcatdog\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"channels_first\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def catdog():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding='same', input_shape=train.shape[1:], activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"First layer...\")\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"Second layer...\")\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"Third layer...\")\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #print(\"Flattening, etc...\")\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Creating model:\")\n",
    "model = catdog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
